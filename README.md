# TP3 : R√©seaux de Neurones Convolutifs (CNN) et Vision par Ordinateur

Ce projet est d√©di√© √† la ma√Ætrise des r√©seaux de neurones convolutifs (CNN) et √† leurs applications fondamentales en vision par ordinateur, allant de la classification d'images complexes (CIFAR-10) au transfert de style neuronal.

## Objectifs du Projet

*   **Fondamentaux des CNN** : Mise en ≈ìuvre des couches `Conv2D` et `MaxPooling2D` pour l'extraction de caract√©ristiques spatiales.
*   **Classification d'images** : Entra√Ænement d'un mod√®le performant sur le jeu de donn√©es **CIFAR-10** (images couleur 32x32 r√©parties en 10 classes).
*   **Architectures Avanc√©es** : Impl√©mentation de blocs r√©siduels (**ResNet**) avec connexions saut√©es (*skip connections*) pour stabiliser l'apprentissage profond.
*   **Neural Style Transfer** : Utilisation du mod√®le pr√©-entra√Æn√© **VGG16** (poids ImageNet) comme extracteur de caract√©ristiques de style et de contenu.

## Structure du R√©pertoire

```text
.
‚îú‚îÄ‚îÄ cnn_classification.py   # Script principal (Architecture et entra√Ænement CIFAR-10)
‚îú‚îÄ‚îÄ style_transfer_demo.py  # D√©mo d'extraction de features avec VGG16
‚îú‚îÄ‚îÄ requirements.txt        # D√©pendances (TensorFlow, NumPy, Matplotlib)
‚îî‚îÄ‚îÄ README.md               # Documentation
```

## Installation et Utilisation

### 1. Installation
```bash
git clone https://github.com/ud-2/TP_DL.git
cd TP_DL
git checkout tp3

# Installation des d√©pendances (via env global ou local)
pip install -r requirements.txt
```

### 2. Entra√Ænement
Lancez le script pour charger CIFAR-10 et entra√Æner le CNN :
```bash
python cnn_classification.py
```

## üî¨ R√©sultats et Analyse (Ex√©cution R√©elle)

L'entra√Ænement a √©t√© r√©alis√© sur 10 √©poques. Voici les m√©triques obtenues :

*   **Pr√©cision finale sur les donn√©es de test** : **69,74%**
*   **Performance d'entra√Ænement** :
    *   Pr√©cision Entra√Ænement : **96,57%** (Loss: 0.1077)
    *   Pr√©cision Validation : **72,12%** (Loss: 1.3894)

### Analyse du Surapprentissage (Overfitting)
On observe un √©cart significatif entre la pr√©cision d'entra√Ænement (~96%) et la pr√©cision de validation (~72%). Ce comportement est symptomatique d'un **surapprentissage marqu√©** : le mod√®le a "m√©moris√©" les sp√©cificit√©s des donn√©es d'entra√Ænement au lieu de g√©n√©raliser. Cela d√©montre l'importance capitale des techniques de r√©gularisation (Dropout, L2) et de l'augmentation de donn√©es pour des datasets complexes comme CIFAR-10.

### Transfert de Style (VGG16)
Le script `style_transfer_demo.py` a valid√© le chargement des poids **ImageNet** pour VGG16. Le mod√®le est configur√© en mode non-entra√Ænable (`trainable=False`), utilisant les couches `block5_conv2` pour le contenu et les couches de `block1` √† `block5` pour l'extraction statistique du style via les matrices de Gram.

## Concepts Cl√©s
*   **Feature Mapping** : Transformation d'une image RGB en cartes d'activations abstraites.
*   **Invariance Spatiale** : R√¥le du Pooling dans la reconnaissance de motifs peu importe leur position.
*   **Skip Connections** : Capacit√© des ResNets √† apprendre des fonctions identit√©s pour √©viter la d√©gradation du gradient.

---
**Auteurs** : VUIDE OUENDEU FRANCK JORDAN (21P018)  
**Institution** : ENSPY 5GI  
**Date** : Janvier 2026